import json
from datetime import time, datetime

import redis
from requests import Session
from shared import models
from .logger import debug_log, log_error
from shared.models import TaskStatus
from ..database import SessionLocal

# --- 1. æ­»ä¿¡é˜Ÿåˆ—é€»è¾‘ (æ–°å¢) ---
DLQ_STREAM_KEY = "sys_dead_letters"

def send_to_dlq(redis_client, message_id, raw_payload, error_msg, source="Unknown"):
    """
    ğŸ’€ å°†çƒ‚æ¶ˆæ¯ç§»å…¥æ­»ä¿¡é˜Ÿåˆ—ï¼Œå¹¶ ACK ä¸¢å¼ƒ
    """
    try:
        # ç¡®ä¿ message_id æ˜¯å­—ç¬¦ä¸²
        if isinstance(message_id, bytes):
            message_id = message_id.decode()

        # ç¡®ä¿ payload æ˜¯å­—ç¬¦ä¸²
        payload_str = "None"
        if raw_payload:
            payload_str = raw_payload.decode('utf-8', errors='ignore') if isinstance(raw_payload, bytes) else str(
                raw_payload)

        dead_msg = {
            "original_id": message_id,
            "error": str(error_msg),
            "source_worker": source,
            "failed_at": str(int(time.time())),
            "raw_payload": payload_str
        }

        # 1. å…¥æ­»ä¿¡
        redis_client.xadd(DLQ_STREAM_KEY, dead_msg, maxlen=10000)
        debug_log(f"ğŸ’€ å·²ç§»å…¥æ­»ä¿¡é˜Ÿåˆ—: {message_id}", "WARNING")

    except Exception as e:
        debug_log(f"å†™å…¥æ­»ä¿¡é˜Ÿåˆ—å¤±è´¥: {e}", "ERROR")


# --- 2. å®‰å…¨è§£æé€»è¾‘ (æ–°å¢) ---
def parse_and_validate(redis_client, stream_key, group_name, message_id, message_data, consumer_name):
    """
    ğŸ›¡ï¸ é€šç”¨è§£æå‡½æ•°ï¼š
    - å¦‚æœè§£ææˆåŠŸï¼Œè¿”å› task_data (dict)
    - å¦‚æœè§£æå¤±è´¥ï¼ˆJSONé”™è¯¯/ç©ºæ¶ˆæ¯ï¼‰ï¼Œè‡ªåŠ¨å…¥æ­»ä¿¡ + ACKï¼Œå¹¶è¿”å› None
    """
    payload_bytes = message_data.get(b'payload')

    # 1. æ£€æŸ¥ç©ºæ¶ˆæ¯
    if not payload_bytes:
        send_to_dlq(redis_client, message_id, b"", "Empty Payload", consumer_name)
        redis_client.xack(stream_key, group_name, message_id)
        return None

    try:
        # 2. å°è¯•è§£æ JSON
        task_data = json.loads(payload_bytes)
        return task_data

    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        # 3. è§£æå¤±è´¥ -> è‡ªåŠ¨å¤„ç†åäº‹ (DLQ + ACK)
        debug_log(f"æ•°æ®è§£æå¤±è´¥: {e}", "ERROR")
        send_to_dlq(redis_client, message_id, payload_bytes, f"JSON Error: {e}", consumer_name)
        redis_client.xack(stream_key, group_name, message_id)
        return None


def mark_task_failed(db, task_id, error_msg):
    """
    é€šç”¨ä»»åŠ¡å¤±è´¥å¤„ç†é€»è¾‘
    :param db: æ•°æ®åº“ Session å¯¹è±¡
    :param task_id: ä»»åŠ¡ ID
    :param error_msg: é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
    """
    try:
        if task_id and task_id != "UNKNOWN":
            task = db.query(models.Task).filter(models.Task.task_id == task_id).first()
            if task:
                task.status = TaskStatus.FAILED
                task.error_msg = str(error_msg)
                db.commit()
                debug_log(f"ğŸ’¾ ä»»åŠ¡å·²æ ‡è®°ä¸ºå¤±è´¥: {task_id} - {error_msg}", "WARNING")
            else:
                debug_log(f"âš ï¸ æ ‡è®°å¤±è´¥æ—¶æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}", "WARNING")
    except Exception as e:
        db.rollback()
        log_error("TaskHelper", f"æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€æ—¶æ•°æ®åº“é”™è¯¯: {e}", task_id)


def claim_task(db: Session, task_id: str) -> bool:
    """
    ğŸ”¥ æ ¸å¿ƒå¹‚ç­‰æ€§å‡½æ•°ï¼šå°è¯•è®¤é¢†ä»»åŠ¡
    åŸç†ï¼šåˆ©ç”¨æ•°æ®åº“åŸå­æ›´æ–° (UPDATE ... WHERE status=PENDING)

    :param db: æ•°æ®åº“ä¼šè¯
    :param task_id: ä»»åŠ¡ID
    :return: True(æŠ¢å æˆåŠŸï¼Œå¯ä»¥æ‰§è¡Œ), False(å·²è¢«æŠ¢å æˆ–å·²å®Œæˆï¼Œè·³è¿‡)
    """
    try:
        # æ‰§è¡ŒåŸå­æ›´æ–°ï¼šåªæœ‰å½“å‰æ˜¯ PENDING æ—¶æ‰æ›´æ–°ä¸º PROCESSING
        # synchronize_session=False èƒ½æé«˜æ€§èƒ½ï¼Œé˜²æ­¢ SQLAlchemy å°è¯•æ›´æ–°å†…å­˜å¯¹è±¡
        result = db.query(models.Task).filter(
            models.Task.task_id == task_id,
            models.Task.status == TaskStatus.PENDING
        ).update(
            {"status": TaskStatus.PROCESSING},
            synchronize_session=False
        )

        db.commit()

        if result == 1:
            debug_log(f"ğŸ”’ æˆåŠŸé”å®šä»»åŠ¡: {task_id} -> PROCESSING", "INFO")
            return True
        else:
            # result == 0 è¯´æ˜æ‰¾ä¸åˆ°ç¬¦åˆæ¡ä»¶(IDåŒ¹é…ä¸”çŠ¶æ€ä¸ºPENDING)çš„è®°å½•
            # è¿™æ„å‘³ç€ä»»åŠ¡å¯èƒ½æ­£åœ¨è¢«åˆ«äººå¤„ç†(PROCESSING)æˆ–è€…å·²ç»å®Œæˆ(SUCCESS/FAILED)
            debug_log(f"âœ‹ ä»»åŠ¡æŠ¢å å¤±è´¥ (å·²è¢«å¤„ç†): {task_id}", "WARNING")
            return False

    except Exception as e:
        db.rollback()
        log_error("TaskHelper", f"æŠ¢å ä»»åŠ¡æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯: {e}", task_id)
        return False


def recover_pending_tasks(
        redis_client: redis.Redis,
        stream_key: str,
        group_name: str,
        consumer_name: str,
        process_callback
):
    try:
        # è·å–æ‰€æœ‰å·²è®¤é¢†ä½†æœª ACK çš„æ¶ˆæ¯ (Start from '0')
        response = redis_client.xreadgroup(
            group_name, consumer_name, {stream_key: '0'}, count=50, block=None
        )

        if response:
            stream_name, messages = response[0]
            if messages:
                debug_log(f"â™»ï¸  [{consumer_name}] æ­£åœ¨æ¢å¤ {len(messages)} ä¸ªæŒ‚èµ·ä»»åŠ¡...", "WARNING")

                # è·å–æ•°æ®åº“ä¼šè¯ï¼Œç”¨äºæ‰¹é‡ä¿®å¤çŠ¶æ€
                db = SessionLocal()

                try:
                    for message_id, message_data in messages:
                        # --- 1. å°è¯•è§£æå¹¶ä¿®å¤åƒµå°¸çŠ¶æ€ ---
                        try:
                            # Redis çš„ message_id (å¦‚ "1678888888888-0") å‰åŠéƒ¨åˆ†æ˜¯æ—¶é—´æˆ³(æ¯«ç§’)
                            msg_timestamp = int(message_id.decode().split('-')[0])
                            current_time = int(time.time() * 1000)

                            # å¦‚æœæ¶ˆæ¯è¶…è¿‡ 60 ç§’ï¼ˆå³æ—¶èŠå¤©çš„å®¹å¿åº¦ï¼‰ï¼Œç›´æ¥ä¸¢å¼ƒ
                            if current_time - msg_timestamp > 60000:
                                print(f"â° ä¸¢å¼ƒè¿‡æœŸä»»åŠ¡: {message_id} (è¶…æ—¶ > 60s)")
                                redis_client.xack(stream_key, group_name, message_id)
                                continue  # è·³è¿‡ï¼Œä¸æ‰§è¡Œ

                            payload_bytes = message_data.get(b'payload')
                            if payload_bytes:
                                task_data = json.loads(payload_bytes)
                                task_id = task_data.get('task_id')

                                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœä»»åŠ¡çŠ¶æ€æ˜¯ PROCESSINGï¼Œè¯´æ˜æ˜¯ä¸Šæ¬¡å´©æºƒç•™ä¸‹çš„
                                # å¿…é¡»å¼ºåˆ¶é‡ç½®ä¸º PENDINGï¼Œå¦åˆ™åç»­ claim_task ä¼šæŠ¢å å¤±è´¥
                                if task_id:
                                    result = db.query(models.Task).filter(
                                        models.Task.task_id == task_id,
                                        models.Task.status == TaskStatus.PROCESSING
                                    ).update(
                                        {"status": TaskStatus.PENDING},
                                        synchronize_session=False
                                    )
                                    if result > 0:
                                        db.commit()
                                        debug_log(f"ğŸ”§ [è‡ªæ„ˆ] ä¿®å¤åƒµå°¸ä»»åŠ¡: {task_id} PROCESSING -> PENDING", "INFO")

                        except Exception as e:
                            debug_log(f"é¢„æ£€æŸ¥è§£æå¤±è´¥ (å°†ç”± Worker è‡ªåŠ¨å¤„ç†): {e}", "WARNING")
                            # è§£æéƒ½å¤±è´¥äº†ï¼Œé€šå¸¸å»ºè®®ç›´æ¥ ACK è·³è¿‡ï¼Œé˜²æ­¢æ­»å¾ªç¯
                            # redis_client.xack(stream_key, group_name, message_id)
                            # continue

                        # --- 2. è°ƒç”¨å…·ä½“çš„ Worker é€»è¾‘è¿›è¡Œå¤„ç† ---
                        # check_idempotency=True ä¾ç„¶é‡è¦ï¼Œé˜²æ­¢å¤„ç†é‚£äº›å…¶å®å·²ç» SUCCESS ä½†æ²¡ ACK çš„ä»»åŠ¡
                        process_callback(message_id, message_data, check_idempotency=True)

                finally:
                    db.close()

                debug_log("âœ… æŒ‚èµ·ä»»åŠ¡å¤„ç†å®Œæ¯•", "INFO")

    except Exception as e:
        debug_log(f"âŒ æ¢å¤ Pending ä»»åŠ¡æµç¨‹å¤±è´¥: {e}", "ERROR")


def finish_task_success(db, task_id, response_text, cost_time, conversation_id=None):
    """
    âœ… é€šç”¨ä»»åŠ¡æˆåŠŸå¤„ç†é€»è¾‘
    1. æŸ¥è¯¢ä»»åŠ¡ (æ‡’åŠ è½½)
    2. æ›´æ–°çŠ¶æ€ã€ç»“æœã€è€—æ—¶
    3. æ›´æ–°ä¼šè¯æ—¶é—´
    4. æäº¤äº‹åŠ¡
    """
    try:
        # 1. æŸ¥è¯¢ä»»åŠ¡
        task = db.query(models.Task).filter(models.Task.task_id == task_id).first()

        if task:
            # 2. æ›´æ–°ä»»åŠ¡å­—æ®µ
            task.response_text = response_text
            task.status = TaskStatus.SUCCESS
            task.cost_time = cost_time
            task.updated_at = datetime.now()

            # 3. æ›´æ–°ä¼šè¯æœ€åæ´»è·ƒæ—¶é—´ (å¦‚æœæœ‰)
            if conversation_id:
                conv = db.query(models.Conversation).filter(
                    models.Conversation.conversation_id == conversation_id
                ).first()
                if conv:
                    conv.updated_at = datetime.now()

            # 4. æäº¤
            db.commit()
            debug_log(f"âœ… ä»»åŠ¡å®Œæˆ: {task_id} (è€—æ—¶: {cost_time}s)", "SUCCESS")
            return True
        else:
            debug_log(f"âš ï¸ ä¿å­˜ç»“æœæ—¶æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}", "WARNING")
            return False

    except Exception as e:
        db.rollback()
        log_error("WorkerUtils", f"ä¿å­˜ä»»åŠ¡ç»“æœå¤±è´¥: {e}", task_id)
        return False


def process_ai_result(db, task_id, ai_text, cost_time, conversation_id=None, refusal_keywords=None):
    """
    âš–ï¸ é€šç”¨ AI ç»“æœå¤„ç†å‡½æ•° (ç»ˆå®¡æ³•å®˜)

    1. è½¯æ‹’ç»æ£€æµ‹ (Soft Rejection Check): æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«æ‹’ç»å…³é”®è¯
    2. å¦‚æœå‘½ä¸­ -> è‡ªåŠ¨æ ‡è®°ä¸ºå¤±è´¥ (FAILED)
    3. å¦‚æœé€šè¿‡ -> è‡ªåŠ¨æ ‡è®°ä¸ºæˆåŠŸ (SUCCESS) å¹¶ä¿å­˜

    :param refusal_keywords: æ‹’ç»è¯åˆ—è¡¨ (List[str])ï¼Œå¦‚æœä¸ä¼ åˆ™ä¸æ£€æŸ¥
    :return: True(æˆåŠŸä¿å­˜), False(è¢«æ‹’ç»æˆ–å‡ºé”™)
    """
    try:
        # --- 1. è½¯æ‹’ç»æ£€æµ‹ ---
        if refusal_keywords:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®è¯
            is_refusal = any(keyword in ai_text for keyword in refusal_keywords)

            if is_refusal:
                error_msg = f"AI æ‹’ç»ç”Ÿæˆ: {ai_text[:100]}..."  # åªæˆªå–å‰100å­—é¿å…æ—¥å¿—è¿‡é•¿
                debug_log(f"ğŸ›‘ æ•è·åˆ°è½¯æ‹’ç»: {error_msg}", "WARNING")

                # ç›´æ¥è°ƒç”¨åŒæ–‡ä»¶çš„å¤±è´¥å¤„ç†å‡½æ•°
                mark_task_failed(db, task_id, f"ç”Ÿæˆå¤±è´¥: {ai_text}")
                return False

        # --- 2. å®¡æ ¸é€šè¿‡ï¼Œä¿å­˜ç»“æœ ---
        # ç›´æ¥è°ƒç”¨ä¸Šä¸€è½®æˆ‘ä»¬å°è£…å¥½çš„æˆåŠŸå¤„ç†å‡½æ•°
        return finish_task_success(db, task_id, ai_text, cost_time, conversation_id)

    except Exception as e:
        debug_log(f"å¤„ç† AI ç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", "ERROR")
        return False